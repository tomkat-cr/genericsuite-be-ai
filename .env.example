######################################
# GenericSuite General Configuration #
######################################
#
# Aplicacion name
APP_NAME=ExampleApp
# Aplicacion domain
APP_DOMAIN_NAME=exampleapp.com
# Aplicacion AI assistant name
AI_ASSISTANT_NAME=ExampleBot
# Application default language
DEFAULT_LANG=en
#
# # PROD
# APP_DEBUG=0
# APP_STAGE=prod
# # QA
# APP_DEBUG=1
# APP_STAGE=qa
# DEV
# Application debug (0,1)
APP_DEBUG=1
# Application environment: dev, qa, staging, prod
# APP_STAGE=dev
# Application super admin email
APP_SUPERADMIN_EMAIL=xxxx
# Application secret ket (to set password encryption)
APP_SECRET_KEY=xxxx
# Storage seed (to set storage URL encryption -e.g. AWS S3-)
STORAGE_URL_SEED=yyy
#
# Database configuration
#
# For AWS DynamoDB
# # DEV: docker
# APP_DB_ENGINE_DEV=DYNAMO_DB
# APP_DB_NAME_DEV=
# APP_DB_URI_DEV=http://localhost:8000
# # QA: AWS DynamoDB
# APP_DB_ENGINE_QA=DYNAMO_DB
# APP_DB_NAME_QA=
# APP_DB_URI_QA=
# # PROD: AWS DynamoDB
# APP_DB_ENGINE_PROD=DYNAMO_DB
# APP_DB_NAME_PROD=
# APP_DB_URI_PROD=
# # DEMO: AWS DynamoDB
# APP_DB_ENGINE_DEMO=DYNAMO_DB
# APP_DB_NAME_DEMO=
# APP_DB_URI_DEMO=
#
# For MongoDB
# DEV: Docker container
APP_DB_ENGINE_DEV=MONGO_DB
APP_DB_NAME_DEV=mongo
APP_DB_URI_DEV=mongodb://root:example@app.exampleapp.local:27017/
APP_CORS_ORIGIN_DEV=*
AWS_S3_CHATBOT_ATTACHMENTS_BUCKET_DEV=aws-s3-bucket-name
# QA: MongoDB Atlas
APP_DB_ENGINE_QA=MONGO_DB
APP_DB_NAME_QA=xxxx
APP_DB_URI_QA=mongodb+srv://<user>:<password>@<cluster>.mongodb.net
APP_CORS_ORIGIN_QA=*
APP_CORS_ORIGIN_QA_CLOUD=https://app-qa.exampleapp.com
APP_CORS_ORIGIN_QA_LOCAL=http://localhost:3000
AWS_S3_CHATBOT_ATTACHMENTS_BUCKET_QA=aws-s3-bucket-name
# Staging: MongoDB Atlas
APP_DB_ENGINE_STAGING=MONGO_DB
APP_DB_NAME_STAGING=xxxx
APP_DB_URI_STAGING=mongodb+srv://<user>:<password>@<cluster>.mongodb.net
APP_CORS_ORIGIN_STAGING=https://app-staging.exampleapp.com
AWS_S3_CHATBOT_ATTACHMENTS_BUCKET_STAGING=aws-s3-bucket-name
# PROD: MongoDB Atlas
APP_DB_ENGINE_PROD=MONGO_DB
APP_DB_NAME_PROD=xxxx
APP_DB_URI_PROD=mongodb+srv://<user>:<password>@<cluster>.mongodb.net
APP_CORS_ORIGIN_PROD=https://app.exampleapp.com
AWS_S3_CHATBOT_ATTACHMENTS_BUCKET_PROD=aws-s3-bucket-name
# DEMO: MongoDB Atlas
APP_DB_ENGINE_DEMO=MONGO_DB
APP_DB_NAME_DEMO=xxxx
APP_DB_URI_DEMO=mongodb+srv://<user>:<password>@<cluster>.mongodb.net
APP_CORS_ORIGIN_DEMO=https://app-demo.exampleapp.com
AWS_S3_CHATBOT_ATTACHMENTS_BUCKET_DEMO=aws-s3-bucket-name
#
# Current framkework options: chalice, flask, fastapi
CURRENT_FRAMEWORK=chalice
#
# JSON configuration files location and git URL
GIT_SUBMODULE_LOCAL_PATH=lib/config_dbdef
GIT_SUBMODULE_URL=git://github.com/username/configs_repo_name.git
#
# Forntend application path (to copy version file during big lambdas deployment)
FRONTEND_PATH=../exampleapp_frontend
#
# Local python version
PYTHON_VERSION=3.11.5
#
# IAAS Cloud provider
# Available options: `aws`, `gcp`, `azure`
CLOUD_PROVIDER=aws
#
# Enable/disable Cloud Provider secrets (instead of environment variables).
# Available options: `1` to enable, `0` to disable. Defaults to: 1
# GET_SECRETS_ENABLED=0
#
# Fine grained Cloud Provider secrets management:
#
# Enable/disable Cloud Provider envvars.
# Available options: `1` to enable, `0` to disable. Defaults to: 1
# Set to "0" in local development environment so envvars like APP_CORS_ORIGIN can be
# set by the scripts and .env file and access QA resources from DEV.
# GET_SECRETS_ENVVARS=0
#
# Enable/disable Cloud Provider critical secrets.
# Available options: `1` to enable, `0` to disable. Defaults to: 1
# Set to "0" in local development environment so envvars like APP_DB_URI can be
# set by the scripts and .env file and access QA resources from DEV.
# GET_SECRETS_CRITICAL=0
#
# AWS Configuration
# https://console.aws.amazon.com
#
# Region for this App all AWS services
AWS_REGION=aws-region
#
# AWS Deployment type
# Available options: `lambda`, `fargate`, `ec2`. Defaults to: lambda
AWS_DEPLOYMENT_TYPE=lambda
#
# AWS base name for Lambda Functions, API Gateway, EC2, ELB, etc.
AWS_LAMBDA_FUNCTION_NAME=aws-lambda-function-name
#
# AWS Lambda function role:
# These variables are used only if deploy without AWS SAM (deploy_without_sam) in big_lambdas_manager.sh. SAM generates this role automatically
AWS_LAMBDA_FUNCTION_ROLE_QA=exampleapp-api_handler-role-qa
AWS_LAMBDA_FUNCTION_ROLE_STAGING=exampleapp-api_handler-role-staging
AWS_LAMBDA_FUNCTION_ROLE_DEMO=exampleapp-api_handler-role-demo
AWS_LAMBDA_FUNCTION_ROLE_PROD=exampleapp-api_handler-role-prod
#
# AWS SSL certificate ARN (used by big_lambdas_manager.sh)
AWS_SSL_CERTIFICATE_ARN=arn:aws:acm:AWS-REGION:AWS-ACCOUNT:certificate/AWS-CERTIFICATE-UUID
#
# AWS S3 bucket name (used by set_fe_cloudfront_domain.sh to set the CloudFront domain name in the frontend for the CORS config)
AWS_S3_BUCKET_NAME_FE=aws-s3-bucket-name
#
# Development URL masking external hostname (for features like AI Vision)
URL_MASK_EXTERNAL_HOSTNAME=app-dev.exampleapp.com
#
# SMTP Mail configuration
SMTP_SERVER=smtp_server
SMTP_PORT=smtp_port
SMTP_USER=smtp_user
SMTP_PASSWORD=smtp_password
SMTP_DEFAULT_SENDER=sender_email
#
# Docker configuration
DOCKER_ACCOUNT=docker_account_username
#
# Local development environment run configuration
#
# Options are: uvicorn, gunicorn, chalice, chalice_docker
#
# Chalice case: "chalice" to use http (running without docker) or "chalice_docker" to use https (with docker)
# http:
# RUN_METHOD="chalice"
# https:
RUN_METHOD="chalice_docker"
#
# Tests configuration
#
# Testing endpoint
TEST_APP_URL=http://app.exampleapp.local:5002
#
# Default App main code directory
# for Chalice:
# https://aws.github.io/chalice/topics/packaging.html
# APP_DIR='.'
# for FastAPI:
# https://fastapi.tiangolo.com/tutorial/bigger-applications/?h=directory+structure#an-example-file-structure
# APP_DIR='app'
# for Flask:
# https://flask.palletsprojects.com/en/2.3.x/tutorial/layout/
# APP_DIR='flaskr'
#
# Default App entry point code file
# for Chalice:
# https://aws.github.io/chalice/topics/packaging.html
# APP_MAIN_FILE='app'
# for FastAPI:
# https://fastapi.tiangolo.com/tutorial/bigger-applications/?h=directory+structure#an-example-file-structure
# APP_MAIN_FILE='main'
# for Flask:
# https://flask.palletsprojects.com/en/2.3.x/tutorial/factory/
# APP_MAIN_FILE='__init__'
#
# Flask configuration
FLASK_APP=index.py
#
# Local frontend port (defautls to 3000)
FRONTEND_LOCAL_PORT=3000
# Local backend API port (defaults to 5001)
BACKEND_LOCAL_PORT=5001
#
####################
# AI Configuration #
####################
#
# AI technology (openai/langchain APIs)
# AI_TECHNOLOGY="openai"
AI_TECHNOLOGY="langchain"
#
# LangChain defaut LLM/Chat model
#
LANGCHAIN_DEFAULT_MODEL=openai
# LANGCHAIN_DEFAULT_MODEL=anthropic
# LANGCHAIN_DEFAULT_MODEL=gs_huggingface
# LANGCHAIN_DEFAULT_MODEL=huggingface_remote
# LANGCHAIN_DEFAULT_MODEL=huggingface
# LANGCHAIN_DEFAULT_MODEL=huggingface_pipeline
# LANGCHAIN_DEFAULT_MODEL=groq
# LANGCHAIN_DEFAULT_MODEL=gemini
# LANGCHAIN_DEFAULT_MODEL=vertexai
# LANGCHAIN_DEFAULT_MODEL=bedrock
# LANGCHAIN_DEFAULT_MODEL=ollama
# LANGCHAIN_DEFAULT_MODEL=aimlapi
# LANGCHAIN_DEFAULT_MODEL=nvidia
# LANGCHAIN_DEFAULT_MODEL=rhymes
# LANGCHAIN_DEFAULT_MODEL=xai
# LANGCHAIN_DEFAULT_MODEL=together
# LANGCHAIN_DEFAULT_MODEL=openrouter
# LANGCHAIN_DEFAULT_MODEL=ibm
# LANGCHAIN_DEFAULT_MODEL=clarifai
#
####################
#
# OpenAI
#
# https://platform.openai.com/api-keys
OPENAI_API_KEY=openai_api_key
# https://openai.com/api/pricing/
OPENAI_MODEL=gpt-5-nano
#
OPENAI_TEMPERATURE=0.5
# OPENAI_MAX_TOKENS=""
# OPENAI_TOP_P="1"
#
# Google API
#
# https://console.cloud.google.com/apis/credentials
GOOGLE_API_KEY=google_console_api_key
# https://programmablesearchengine.google.com/
GOOGLE_CSE_ID=google_console_cse_key
#
# Google Vertex AI
#
# https://cloud.google.com/docs/authentication/application-default-credentials#GAC
GOOGLE_CLOUD_PROJECT=google_cloud_project
# GOOGLE_CLOUD_LOCATION="us-central1"
# GOOGLE_APPLICATION_CREDENTIALS="./service_account.json"
#
# https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference
VERTEXAI_MODEL="gemini-2.0-flash-001"
#
# Hugging Face
#
# https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=huggingface_api_key
HUGGINGFACE_DEFAULT_CHAT_MODEL=mistralai/Mistral-7B-Instruct-v0.2
HUGGINGFACE_DEFAULT_IMG_GEN_MODEL=black-forest-labs/FLUX.1-schnell
#
# Anthropic
#
# https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=anthropic_api_key
ANTHROPIC_MODEL=claude-3-5-sonnet-20240620
#
# Groq
#
# https://console.groq.com/keys
GROQ_API_KEY=groq_api_key
GROQ_MODEL=mixtral-8x7b-32768
#
# AI/ML API
#
# https://aimlapi.com/app/keys
# https://docs.aimlapi.com/api-overview/model-database/text-models
AIMLAPI_API_KEY=aimlapi_api_key
#
AIMLAPI_MODEL_NAME=o1-mini
# AIMLAPI_MODEL_NAME=o1-preview
#
# AIMLAPI_TEMPERATURE=1
# AIMLAPI_MAX_TOKENS=""
# AIMLAPI_TOP_P="1"
#
# Together.ai
#
# https://api.together.xyz/settings/api-keys
# https://api.together.xyz/models
TOGETHER_API_KEY=together_api_key
TOGETHER_MODEL_NAME="meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo"
#
# OpenRouter
#
# https://openrouter.ai/settings/keys
# https://openrouter.ai/models
OPENROUTER_API_KEY=openrouter_api_key
# OPENROUTER_MODEL_NAME=google/gemini-2.0-flash-lite-001
# OPENROUTER_MODEL_NAME=openai/gpt-4o-mini-2024-07-18
#
# xAI (Grok)
#
# https://console.x.ai
# https://docs.x.ai/docs/models?cluster=us-east-1
XAI_API_KEY=xai_api_key
# XAI_MODEL_NAME=grok-2
#
# Nvidia NIMs
#
# https://www.nvidia.com/en-us/account/
NVIDIA_API_KEY=nvidia_api_key
#
NVIDIA_MODEL_NAME=nvidia/llama-3.1-nemotron-70b-instruct
#
# NVIDIA_TEMPERATURE=0.5
# NVIDIA_MAX_TOKENS=
# NVIDIA_TOP_P=1
#
# Rhymes.ai
#
# https://rhymes.ai
RHYMES_CHAT_API_KEY=rhymes_chat_api_key
RHYMES_VIDEO_API_KEY=rhymes_video_api_key
#
# https://rhymes.ai/blog-details/aria-first-open-multimodal-native-moe-model
# RHYMES_CHAT_MODEL_NAME=aria
# RHYMES_CHAT_TEMPERATURE=0.5
# RHYMES_CHAT_MAX_TOKENS=
# RHYMES_CHAT_TOP_P=1
#
# https://rhymes.ai/blog-details/allegro-advanced-video-generation-model
# RHYMES_VIDEO_MODEL_NAME=allegro
# RHYMES_VIDEO_NUM_STEP=50
# RHYMES_VIDEO_CFG_SCALE=7.5
#
# IBM watsonx
#
# https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-credentials.html?context=wx&audience=wdp
# https://cloud.ibm.com/docs/account?topic=account-iamtoken_from_apikey#iamtoken_from_apikey
IBM_WATSONX_PROJECT_ID=ibm_watsonx_project_id
IBM_WATSONX_API_KEY=ibm_watsonx_api_key
#
# https://dataplatform.cloud.ibm.com/samples?context=wx
IBM_WATSONX_MODEL_NAME="ibm/granite-3-2-8b-instruct"
# IBM_WATSONX_MODEL_NAME="meta-llama/llama-3-1-70b-instruct"
#
# Ollama
#
#OLLAMA_BASE_URL=localhost:11434
#
# https://ollama.ai/models
OLLAMA_MODEL_NAME=llama3.2
#
# Eleven Labs
#
# https://elevenlabs.io/app/subscription
ELEVENLABS_API_KEY=elevenlabs_api_key
#
# Cohere
#
# https://dashboard.cohere.com/api-keys
COHERE_API_KEY=cohere_api_key
#
# Pinecone
#
# https://app.pinecone.io/keys
PINECONE_API_KEY=pinecone_api_key
PINECONE_ENV=pinecone_env
#
# Vectara
#
# https://console.vectara.com/console/apiAccess/personalApiKey
VECTARA_CUSTOMER_ID=vectara_customer_id
VECTARA_CORPUS_ID=vectara_corpus_id
VECTARA_API_KEY=vectara_api_key
#
# Weaviate
#
# https://console.weaviate.cloud/dashboard
WEAVIATE_URL=weaviate_url
WEAVIATE_API_KEY=weaviate_api_key
#
####################
#
# Langchain/LangSmith
#
# https://smith.langchain.com/settings
# LANGCHAIN_API_KEY=langchain_api_key
# LANGCHAIN_PROJECT=langchain_project
